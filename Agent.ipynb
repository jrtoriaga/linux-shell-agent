{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfad578e-abc8-48af-9643-a7800e46828e",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6be7b1-5c49-41f9-a0d8-ee1500f5fde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2841e0c3-2417-482f-934a-2f39062e6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe7023-9566-455e-bf01-8552875f68b0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af39af5-97b9-460e-ab88-663e9549bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "        model='gemini-2.5-flash',\n",
    "        timeout=None,\n",
    "        max_retries=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f669d79-761c-4138-88bf-d87e0f62d2cb",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7f89d5-a204-4769-8a7e-7566d47319f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ShellTool\n",
    "\n",
    "shell_tool = ShellTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54db9db5-b63d-436a-aeb8-d2e55506613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional tools for specific CRUD file operations\n",
    "from tools import create_file_tool, read_text_file_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47affeff",
   "metadata": {},
   "source": [
    "### Tavily Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "tavily_tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    include_images=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15843e2",
   "metadata": {},
   "source": [
    "### Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98481696-2af4-4718-ac15-e7cd42b52f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [shell_tool, create_file_tool, read_text_file_tool, tavily_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d18a5-5da4-43e4-ad9c-db70d5b3a06d",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de71f28-12e9-4c2e-89d7-f6245b5551d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "memory = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa1f80-ee0f-4ae0-abb5-93a1a20caddc",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5950ae-dabc-4875-a8f8-51cf0f809a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are the user's devoted linux shell agent, responding with charm, wit, and a warm male British accent. Your sole aim is to help the user accomplish tasks on his computer.\n",
    "\n",
    "You can run bash commands via a shell tool. Never say you're \"running a tool / command\"—speak naturally, as if you're doing it yourself. For example, instead of saying 'I will run the ls -l command,' say 'I'll take a look at the files in that directory for you.' For sensitive or risky commands, explain the potential impact and ask the user's permission. If a task is impossible, let him know clearly.\n",
    "\n",
    "When a task involves multiple steps, ensure commands are logically ordered (e.g., create a directory before touching a file inside it). If an error occurs, try up to three times; after that, stop and explain the issue. Be proactive—correct mistakes automatically when possible.\n",
    "\n",
    "Always seek clarification from the user if a command lacks enough detail.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55806af2-2b85-4906-8e02-7ccc8fb23817",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ae72a9-2768-4795-830b-08bba1b3bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(llm, tools=tools, checkpointer=memory, prompt=prompt)\n",
    "config = {'configurable': {'thread_id': 'agent1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea7627f-26d9-491a-b9f5-a61e517534e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9d9ae-6815-48b0-81a5-7d94b6714ed9",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be0d3e-abd3-4c50-a385-823380835735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    while True:\n",
    "        message = input('\\nUser: ')\n",
    "        if message.lower() == 'quit' or message.lower() == 'exit':\n",
    "            print('\\nExiting. Talk to you again.\\n')\n",
    "            break\n",
    "\n",
    "        for step in agent.stream(\n",
    "            {'messages': [HumanMessage(message)]},\n",
    "            stream_mode='values',\n",
    "            config=config\n",
    "        ):\n",
    "            step['messages'][-1].pretty_print()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
